{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "url = 'https://github.com/chungyiweng/chungyiweng.github.io/commits/main/'\n",
    "page = requests.get(url)\n",
    "print(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "OWNER = \"chungyiweng\" #username\n",
    "REPO = \"chungyiweng.github.io\"  #repo\n",
    "BRANCH = \"main\" #compare to \n",
    "API_BASE_URL = f\"https://api.github.com/repos/{OWNER}/{REPO}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"{API_BASE_URL}/commits?sha={BRANCH}\"\n",
    "response = requests.get(url)\n",
    "commits = response.json()\n",
    "commits_len= len(commits)\n",
    "#commits[0] is the latest commit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def extract_old_new_from_patch(patch_text):\n",
    "    old_version = []\n",
    "    new_version = []\n",
    "    \n",
    "    for line in patch_text.split(\"\\n\"):\n",
    "        if line.startswith(\"---\") or line.startswith(\"+++\"):  # Ignore file headers\n",
    "            continue\n",
    "        elif line.startswith(\"-\") and not line.startswith(\"--\"):\n",
    "            old_version.append(line[1:].strip())  \n",
    "        elif line.startswith(\"+\") and not line.startswith(\"++\"):\n",
    "            new_version.append(line[1:].strip())  \n",
    "    \n",
    "    return old_version, new_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that compares two commits and returns dictionary\n",
    "def compare_commit(commit1, commit2):\n",
    "    url1 = f\"{API_BASE_URL}/compare/{commit2}...{commit1}\"\n",
    "    response1 = requests.get(url1)\n",
    "    diff_data = response1.json()    \n",
    "    return diff_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<Response [404]>\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#compare every two adjacent commits:\n",
    "df_list = []\n",
    "for i in range (0,commits_len-1):\n",
    "    #compare commits[i] and commits[i+1]\n",
    "    commit1 = commits[i]['sha']\n",
    "    commit2 = commits[i+1]['sha']\n",
    "    diff_data = compare_commit(commit1, commit2)\n",
    "    column_names = ['url', 'commit message', 'file name', 'file status', 'page before commit', 'section modified', 'page after commit', 'new section']\n",
    "    url = 'https://github.com/chungyiweng/chungyiweng.github.io/commits/main/'\n",
    "    message = diff_data['commits'][0]['commit']['message']\n",
    "    if \"files\" in diff_data:\n",
    "        files = diff_data.get(\"files\", [])\n",
    "        for file in files:\n",
    "            file_name = file['filename']\n",
    "            url1 = f\"https://raw.githubusercontent.com/{OWNER}/{REPO}/{commit2}/{file_name}\"\n",
    "            url2 = f\"https://raw.githubusercontent.com/{OWNER}/{REPO}/{commit1}/{file_name}\"\n",
    "            status = file['status']\n",
    "            if \"patch\" in file:\n",
    "                    patch1 = file[\"patch\"]\n",
    "                    diff_tuple = extract_old_new_from_patch(patch1)\n",
    "                    old = diff_tuple[0]\n",
    "                    new = diff_tuple[1]\n",
    "                    print(requests.get(url1))\n",
    "                    if requests.get(url1).status_code != 200:\n",
    "                        html_before = \"page does not exist\"\n",
    "                    else:\n",
    "                        html_before = requests.get(url1).text\n",
    "                    html_after = requests.get(url2).text\n",
    "                    soup_before = BeautifulSoup(html_before, \"html.parser\").prettify()\n",
    "                    soup_after =  BeautifulSoup(html_after, \"html.parser\").prettify()\n",
    "                    df_list.append([url, message, file_name, status, soup_before, old, soup_after, new])\n",
    "            else:\n",
    "                    patch1= \"no changes\"\n",
    "                    df_list.append([url, message, file_name, status, \"\", \"\", \"\", \"\"])\n",
    "            \n",
    "            \n",
    "        \n",
    "                 \n",
    "    #each commmit could have more than one file modified\n",
    "    #extract data from diff_data and upload to pd df\n",
    "df = pd.DataFrame(df_list, columns =column_names)\n",
    "df.head(10)\n",
    "df.to_csv(\"data.csv\", index=False)\n",
    "#handle cases where patch is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
